digraph {
	graph [size="48.449999999999996,48.449999999999996"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1663184490968 [label="
 (256)" fillcolor=darkolivegreen1]
	1663184470536 [label=ViewBackward0]
	1663184470760 -> 1663184470536
	1663184470760 [label=SigmoidBackward0]
	1663184470648 -> 1663184470760
	1663184470648 [label=AddBackward0]
	1663184470872 -> 1663184470648
	1663184470872 [label=AddBackward0]
	1663184471040 -> 1663184470872
	1663184471040 [label=AddmmBackward0]
	1663184471208 -> 1663184471040
	1663184380456 [label="linear.linear.bias
 (1)" fillcolor=lightblue]
	1663184380456 -> 1663184471208
	1663184471208 [label=AccumulateGrad]
	1663184471264 -> 1663184471040
	1663184471264 [label=TBackward0]
	1663184470424 -> 1663184471264
	1663184380376 [label="linear.linear.weight
 (1, 13)" fillcolor=lightblue]
	1663184380376 -> 1663184470424
	1663184470424 [label=AccumulateGrad]
	1663184471096 -> 1663184470872
	1663184471096 [label=AddmmBackward0]
	1663184471320 -> 1663184471096
	1663184446712 [label="cin_network.fc.bias
 (1)" fillcolor=lightblue]
	1663184446712 -> 1663184471320
	1663184471320 [label=AccumulateGrad]
	1663184471432 -> 1663184471096
	1663184471432 [label=SumBackward1]
	1663184471544 -> 1663184471432
	1663184471544 [label=CatBackward0]
	1663184471768 -> 1663184471544
	1663184471768 [label=ReluBackward0]
	1663184471936 -> 1663184471768
	1663184471936 [label=ConvolutionBackward0]
	1663184472048 -> 1663184471936
	1663184472048 [label=ViewBackward0]
	1663184472272 -> 1663184472048
	1663184472272 [label=MulBackward0]
	1663183636856 -> 1663184472272
	1663183636856 [label=UnsqueezeBackward0]
	1663184472552 -> 1663183636856
	1663184472552 [label=StackBackward0]
	1663184472720 -> 1663184472552
	1663184472720 [label=EmbeddingBackward0]
	1663184548024 -> 1663184472720
	1663183734248 [label="embed_layers.embed_0.weight
 (49, 16)" fillcolor=lightblue]
	1663183734248 -> 1663184548024
	1663184548024 [label=AccumulateGrad]
	1663184472776 -> 1663184472552
	1663184472776 [label=EmbeddingBackward0]
	1663184548080 -> 1663184472776
	1663183734168 [label="embed_layers.embed_1.weight
 (192, 16)" fillcolor=lightblue]
	1663183734168 -> 1663184548080
	1663184548080 [label=AccumulateGrad]
	1663184472832 -> 1663184472552
	1663184472832 [label=EmbeddingBackward0]
	1663184548248 -> 1663184472832
	1663183845000 [label="embed_layers.embed_2.weight
 (746, 16)" fillcolor=lightblue]
	1663183845000 -> 1663184548248
	1663184548248 [label=AccumulateGrad]
	1663184472888 -> 1663184472552
	1663184472888 [label=EmbeddingBackward0]
	1663184548136 -> 1663184472888
	1663183845080 [label="embed_layers.embed_3.weight
 (627, 16)" fillcolor=lightblue]
	1663183845080 -> 1663184548136
	1663184548136 [label=AccumulateGrad]
	1663184472944 -> 1663184472552
	1663184472944 [label=EmbeddingBackward0]
	1663184548304 -> 1663184472944
	1663183844840 [label="embed_layers.embed_4.weight
 (24, 16)" fillcolor=lightblue]
	1663183844840 -> 1663184548304
	1663184548304 [label=AccumulateGrad]
	1663184473000 -> 1663184472552
	1663184473000 [label=EmbeddingBackward0]
	1663184548360 -> 1663184473000
	1663183844920 [label="embed_layers.embed_5.weight
 (8, 16)" fillcolor=lightblue]
	1663183844920 -> 1663184548360
	1663184548360 [label=AccumulateGrad]
	1663184473056 -> 1663184472552
	1663184473056 [label=EmbeddingBackward0]
	1663184548416 -> 1663184473056
	1663183845480 [label="embed_layers.embed_6.weight
 (703, 16)" fillcolor=lightblue]
	1663183845480 -> 1663184548416
	1663184548416 [label=AccumulateGrad]
	1663184473112 -> 1663184472552
	1663184473112 [label=EmbeddingBackward0]
	1663184548528 -> 1663184473112
	1663183845560 [label="embed_layers.embed_7.weight
 (37, 16)" fillcolor=lightblue]
	1663183845560 -> 1663184548528
	1663184548528 [label=AccumulateGrad]
	1663184473168 -> 1663184472552
	1663184473168 [label=EmbeddingBackward0]
	1663184548584 -> 1663184473168
	1663183845640 [label="embed_layers.embed_8.weight
 (2, 16)" fillcolor=lightblue]
	1663183845640 -> 1663184548584
	1663184548584 [label=AccumulateGrad]
	1663184473224 -> 1663184472552
	1663184473224 [label=EmbeddingBackward0]
	1663184548472 -> 1663184473224
	1663183845720 [label="embed_layers.embed_9.weight
 (593, 16)" fillcolor=lightblue]
	1663183845720 -> 1663184548472
	1663184548472 [label=AccumulateGrad]
	1663184473280 -> 1663184472552
	1663184473280 [label=EmbeddingBackward0]
	1663184548696 -> 1663184473280
	1663183844680 [label="embed_layers.embed_10.weight
 (568, 16)" fillcolor=lightblue]
	1663183844680 -> 1663184548696
	1663184548696 [label=AccumulateGrad]
	1663184473336 -> 1663184472552
	1663184473336 [label=EmbeddingBackward0]
	1663184548752 -> 1663184473336
	1663183845160 [label="embed_layers.embed_11.weight
 (708, 16)" fillcolor=lightblue]
	1663183845160 -> 1663184548752
	1663184548752 [label=AccumulateGrad]
	1663184473392 -> 1663184472552
	1663184473392 [label=EmbeddingBackward0]
	1663184548640 -> 1663184473392
	1663183845240 [label="embed_layers.embed_12.weight
 (522, 16)" fillcolor=lightblue]
	1663183845240 -> 1663184548640
	1663184548640 [label=AccumulateGrad]
	1663184473448 -> 1663184472552
	1663184473448 [label=EmbeddingBackward0]
	1663184548808 -> 1663184473448
	1663183845320 [label="embed_layers.embed_13.weight
 (18, 16)" fillcolor=lightblue]
	1663183845320 -> 1663184548808
	1663184548808 [label=AccumulateGrad]
	1663184473504 -> 1663184472552
	1663184473504 [label=EmbeddingBackward0]
	1663184548864 -> 1663184473504
	1663183845400 [label="embed_layers.embed_14.weight
 (549, 16)" fillcolor=lightblue]
	1663183845400 -> 1663184548864
	1663184548864 [label=AccumulateGrad]
	1663184473560 -> 1663184472552
	1663184473560 [label=EmbeddingBackward0]
	1663184548920 -> 1663184473560
	1663183846120 [label="embed_layers.embed_15.weight
 (681, 16)" fillcolor=lightblue]
	1663183846120 -> 1663184548920
	1663184548920 [label=AccumulateGrad]
	1663184473616 -> 1663184472552
	1663184473616 [label=EmbeddingBackward0]
	1663184549032 -> 1663184473616
	1663184256440 [label="embed_layers.embed_16.weight
 (9, 16)" fillcolor=lightblue]
	1663184256440 -> 1663184549032
	1663184549032 [label=AccumulateGrad]
	1663184473672 -> 1663184472552
	1663184473672 [label=EmbeddingBackward0]
	1663184548976 -> 1663184473672
	1663184256520 [label="embed_layers.embed_17.weight
 (389, 16)" fillcolor=lightblue]
	1663184256520 -> 1663184548976
	1663184548976 [label=AccumulateGrad]
	1663184473728 -> 1663184472552
	1663184473728 [label=EmbeddingBackward0]
	1663184549088 -> 1663184473728
	1663184256600 [label="embed_layers.embed_18.weight
 (136, 16)" fillcolor=lightblue]
	1663184256600 -> 1663184549088
	1663184549088 [label=AccumulateGrad]
	1663184473784 -> 1663184472552
	1663184473784 [label=EmbeddingBackward0]
	1663184549200 -> 1663184473784
	1663184256680 [label="embed_layers.embed_19.weight
 (4, 16)" fillcolor=lightblue]
	1663184256680 -> 1663184549200
	1663184549200 [label=AccumulateGrad]
	1663184473840 -> 1663184472552
	1663184473840 [label=EmbeddingBackward0]
	1663184549144 -> 1663184473840
	1663184256760 [label="embed_layers.embed_20.weight
 (693, 16)" fillcolor=lightblue]
	1663184256760 -> 1663184549144
	1663184549144 [label=AccumulateGrad]
	1663184473896 -> 1663184472552
	1663184473896 [label=EmbeddingBackward0]
	1663184549256 -> 1663184473896
	1663184256840 [label="embed_layers.embed_21.weight
 (6, 16)" fillcolor=lightblue]
	1663184256840 -> 1663184549256
	1663184549256 [label=AccumulateGrad]
	1663184473952 -> 1663184472552
	1663184473952 [label=EmbeddingBackward0]
	1663184549368 -> 1663184473952
	1663184256920 [label="embed_layers.embed_22.weight
 (12, 16)" fillcolor=lightblue]
	1663184256920 -> 1663184549368
	1663184549368 [label=AccumulateGrad]
	1663184474008 -> 1663184472552
	1663184474008 [label=EmbeddingBackward0]
	1663184549312 -> 1663184474008
	1663184379976 [label="embed_layers.embed_23.weight
 (456, 16)" fillcolor=lightblue]
	1663184379976 -> 1663184549312
	1663184549312 [label=AccumulateGrad]
	1663184474064 -> 1663184472552
	1663184474064 [label=EmbeddingBackward0]
	1663184549480 -> 1663184474064
	1663184380056 [label="embed_layers.embed_24.weight
 (30, 16)" fillcolor=lightblue]
	1663184380056 -> 1663184549480
	1663184549480 [label=AccumulateGrad]
	1663184547912 -> 1663184472552
	1663184547912 [label=EmbeddingBackward0]
	1663184549536 -> 1663184547912
	1663184380136 [label="embed_layers.embed_25.weight
 (317, 16)" fillcolor=lightblue]
	1663184380136 -> 1663184549536
	1663184549536 [label=AccumulateGrad]
	1663184472440 -> 1663184472272
	1663184472440 [label=UnsqueezeBackward0]
	1663184472552 -> 1663184472440
	1663184472104 -> 1663184471936
	1663184446312 [label="cin_network.conv_layers.0.weight
 (26, 676, 1)" fillcolor=lightblue]
	1663184446312 -> 1663184472104
	1663184472104 [label=AccumulateGrad]
	1663184472160 -> 1663184471936
	1663184446392 [label="cin_network.conv_layers.0.bias
 (26)" fillcolor=lightblue]
	1663184446392 -> 1663184472160
	1663184472160 [label=AccumulateGrad]
	1663184471824 -> 1663184471544
	1663184471824 [label=ReluBackward0]
	1663184471992 -> 1663184471824
	1663184471992 [label=ConvolutionBackward0]
	1663184472496 -> 1663184471992
	1663184472496 [label=ViewBackward0]
	1663184549424 -> 1663184472496
	1663184549424 [label=MulBackward0]
	1663183636856 -> 1663184549424
	1663184549704 -> 1663184549424
	1663184549704 [label=UnsqueezeBackward0]
	1663184471768 -> 1663184549704
	1663184472328 -> 1663184471992
	1663184446472 [label="cin_network.conv_layers.1.weight
 (26, 676, 1)" fillcolor=lightblue]
	1663184446472 -> 1663184472328
	1663184472328 [label=AccumulateGrad]
	1663184549592 -> 1663184471992
	1663184446552 [label="cin_network.conv_layers.1.bias
 (26)" fillcolor=lightblue]
	1663184446552 -> 1663184549592
	1663184549592 [label=AccumulateGrad]
	1663184471488 -> 1663184471096
	1663184471488 [label=TBackward0]
	1663184471712 -> 1663184471488
	1663184446632 [label="cin_network.fc.weight
 (1, 52)" fillcolor=lightblue]
	1663184446632 -> 1663184471712
	1663184471712 [label=AccumulateGrad]
	1663184470928 -> 1663184470648
	1663184470928 [label=AddmmBackward0]
	1663184471152 -> 1663184470928
	1663184446872 [label="final_linear.bias
 (1)" fillcolor=lightblue]
	1663184446872 -> 1663184471152
	1663184471152 [label=AccumulateGrad]
	1663184471600 -> 1663184470928
	1663184471600 [label=ReluBackward0]
	1663184472216 -> 1663184471600
	1663184472216 [label=AddmmBackward0]
	1663184549816 -> 1663184472216
	1663184380936 [label="dnn_network.dnn_network.2.bias
 (256)" fillcolor=lightblue]
	1663184380936 -> 1663184549816
	1663184549816 [label=AccumulateGrad]
	1663184549648 -> 1663184472216
	1663184549648 [label=ReluBackward0]
	1663184547968 -> 1663184549648
	1663184547968 [label=AddmmBackward0]
	1663184550096 -> 1663184547968
	1663184380776 [label="dnn_network.dnn_network.1.bias
 (512)" fillcolor=lightblue]
	1663184380776 -> 1663184550096
	1663184550096 [label=AccumulateGrad]
	1663184550152 -> 1663184547968
	1663184550152 [label=ReluBackward0]
	1663184549984 -> 1663184550152
	1663184549984 [label=AddmmBackward0]
	1663184550432 -> 1663184549984
	1663184380616 [label="dnn_network.dnn_network.0.bias
 (512)" fillcolor=lightblue]
	1663184380616 -> 1663184550432
	1663184550432 [label=AccumulateGrad]
	1663184550488 -> 1663184549984
	1663184550488 [label=CatBackward0]
	1663184550320 -> 1663184550488
	1663184550320 [label=CatBackward0]
	1663184472720 -> 1663184550320
	1663184472776 -> 1663184550320
	1663184472832 -> 1663184550320
	1663184472888 -> 1663184550320
	1663184472944 -> 1663184550320
	1663184473000 -> 1663184550320
	1663184473056 -> 1663184550320
	1663184473112 -> 1663184550320
	1663184473168 -> 1663184550320
	1663184473224 -> 1663184550320
	1663184473280 -> 1663184550320
	1663184473336 -> 1663184550320
	1663184473392 -> 1663184550320
	1663184473448 -> 1663184550320
	1663184473504 -> 1663184550320
	1663184473560 -> 1663184550320
	1663184473616 -> 1663184550320
	1663184473672 -> 1663184550320
	1663184473728 -> 1663184550320
	1663184473784 -> 1663184550320
	1663184473840 -> 1663184550320
	1663184473896 -> 1663184550320
	1663184473952 -> 1663184550320
	1663184474008 -> 1663184550320
	1663184474064 -> 1663184550320
	1663184547912 -> 1663184550320
	1663184550544 -> 1663184549984
	1663184550544 [label=TBackward0]
	1663184550712 -> 1663184550544
	1663184380536 [label="dnn_network.dnn_network.0.weight
 (512, 429)" fillcolor=lightblue]
	1663184380536 -> 1663184550712
	1663184550712 [label=AccumulateGrad]
	1663184550208 -> 1663184547968
	1663184550208 [label=TBackward0]
	1663184550376 -> 1663184550208
	1663184380696 [label="dnn_network.dnn_network.1.weight
 (512, 512)" fillcolor=lightblue]
	1663184380696 -> 1663184550376
	1663184550376 [label=AccumulateGrad]
	1663184549872 -> 1663184472216
	1663184549872 [label=TBackward0]
	1663184550040 -> 1663184549872
	1663184380856 [label="dnn_network.dnn_network.2.weight
 (256, 512)" fillcolor=lightblue]
	1663184380856 -> 1663184550040
	1663184550040 [label=AccumulateGrad]
	1663184471880 -> 1663184470928
	1663184471880 [label=TBackward0]
	1663184549760 -> 1663184471880
	1663184446792 [label="final_linear.weight
 (1, 256)" fillcolor=lightblue]
	1663184446792 -> 1663184549760
	1663184549760 [label=AccumulateGrad]
	1663184470536 -> 1663184490968
	1663184490808 [label="
 (256, 1)" fillcolor=darkolivegreen3]
	1663184470760 -> 1663184490808
	1663184490808 -> 1663184490968 [style=dotted]
}
